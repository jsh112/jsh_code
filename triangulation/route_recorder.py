#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
route_recorder.py â€” ìˆ™ë ¨ì ë“±ë°˜ ê²½ë¡œ ìº¡ì²˜ ìŠ¤í¬ë¦½íŠ¸ (v3.2, 2025-09-23)

ëª©ì (ë¯¸ë‹ˆë©€ ë¼ë²¨ëŸ¬):
- ìˆ™ë ¨ìê°€ ì‹¤ì œë¡œ ì‚¬ìš©í•œ í™€ë“œë“¤ì„ 'ìˆœì„œëŒ€ë¡œ' CSVë¡œ ì €ì¥
- **í‰ê°€ ê·œì¹™(350ms)ì€ ê¸°ë¡í•˜ì§€ ì•ŠìŒ** â€” ìˆ˜ì§‘ì€ ì¢Œí‘œÂ·ìˆœì„œì—ë§Œ ì§‘ì¤‘
- MediaPipe Poseë¡œ ì†/ë°œ ëœë“œë§ˆí¬ë¥¼ ì¶”ì í•˜ê³ , "í™€ë“œ í´ë¦¬ê³¤ ë‚´ë¶€ì— ì—°ì† Ní”„ë ˆì„(ê¸°ë³¸ 4)" ìˆìœ¼ë©´ ìë™ ì €ì¥
- ì†/ë°œì€ **ìë™ íŒë³„**ë˜ì–´ CSVì˜ `contact_part`ì— ê¸°ë¡
- ìš”ì²­ ë°˜ì˜: **hold_id í¬í•¨**(ì´ˆê¸° ë³‘í•©/ì¸ë±ì‹±ì—ì„œ ë¶€ì—¬ëœ ê³µí†µ ID)

CSV ìŠ¤í‚¤ë§ˆ(default):
seq, hold_id, cxL, cyL, cxR, cyR, X_mm, Y_mm, Z_mm, contact_part, timestamp
  - seq: ê²½ë¡œ ë‚´ ìˆœì„œ(0ë¶€í„°)
  - hold_id: ì´ˆê¸° 10í”„ë ˆì„ ë³‘í•©/ì¸ë±ì‹± ê²°ê³¼ì˜ ê³µí†µ ID(ì„¸ì…˜ë³„ë¡œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)
  - (cxL,cyL)/(cxR,cyR): ì¢Œ/ìš° ì¹´ë©”ë¼ì—ì„œì˜ í™€ë“œ ì¤‘ì‹¬ì  í”½ì…€ ì¢Œí‘œ(ì„¸ê·¸ë¨¼íŠ¸ ì»¨íˆ¬ì–´ ëª¨ë©˜íŠ¸)
  - (X_mm,Y_mm,Z_mm): ì‚¼ê°ì¸¡ëŸ‰í•œ 3D ì¢Œí‘œ(mm, LEFT ì¹´ë©”ë¼ ì¢Œí‘œê³„)
  - contact_part: hand|foot (MediaPipe ëœë“œë§ˆí¬ë¡œ ìë™ íŒë³„)
  - timestamp: í–‰ ì €ì¥ ì‹œê°(Unix epoch). --no_timestampë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥

ì‚¬ìš© ì˜ˆì‹œ:
  python route_recorder.py                                 # ì‹¤í–‰ ì‹œ ìƒ‰ìƒ ì„ íƒ ë©”ë‰´ + routes/ ìë™ ì €ì¥
  python route_recorder.py --colors "orange,blue"          # ì—¬ëŸ¬ ìƒ‰ í—ˆìš©
  python route_recorder.py --colors all --label expertA    # ì „ì²´ í—ˆìš© + íŒŒì¼ëª… ë¼ë²¨
  python route_recorder.py --parts both --confirm_frames 3 # ì†/ë°œ ëª¨ë‘ ì‚¬ìš© + ë””ë°”ìš´ìŠ¤ í”„ë ˆì„ ì¡°ì •

ì£¼ì˜/ì„¤ê³„ ì² í•™:
- **hold_idëŠ” í¸ì˜ìš©**(ì¦‰ì‹œ ì¬ìƒì— ìœ ë¦¬). ë‹¤ë¥¸ ì„¸ì…˜ì—ì„œ ì¬ìƒí•  ë• YOLO ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
  combined_test.pyì—ì„œëŠ” 3D/2D ê·¼ì ‘ ë§¤ì¹­ìœ¼ë¡œ ë³´ì •í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€ ê¶Œì¥.
- yaw/pitchëŠ” ì¬ìƒ ì‹œ(ìµœì‹  ë³´ì •ê°’) ê³„ì‚°ì„ ê¶Œì¥.
"""

import cv2
import numpy as np
import time
import csv
import argparse
from pathlib import Path
from datetime import datetime

# ===== ê²½ë¡œ ì„¤ì • =====
REPO_ROOT = Path(__file__).resolve().parent  # ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€(ë¦¬í¬ ë£¨íŠ¸ë¡œ ì‚¬ìš©)
ROUTES_DIR = REPO_ROOT / "routes"
ROUTES_DIR.mkdir(parents=True, exist_ok=True)

# ìŠ¤í…Œë ˆì˜¤/ëª¨ë¸ ê¸°ë³¸ ê²½ë¡œ(í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
NPZ_PATH   = REPO_ROOT / "calib_out/old_camera_same/stereo/stereo_params_scaled.npz"
MODEL_PATH = REPO_ROOT / "best_6.pt"

# ì¹´ë©”ë¼ ì¸ë±ìŠ¤
CAM1_INDEX = 1   # LEFT (í•„ìš” ì‹œ --left_cam ë¡œ ë®ì–´ì“°ê¸°)
CAM2_INDEX = 2   # RIGHT (í•„ìš” ì‹œ --right_cam ë¡œ ë®ì–´ì“°ê¸°)

# ë””ìŠ¤í”Œë ˆì´/ì…ë ¥ ìŠ¤ì™‘ ì—¬ë¶€
SWAP_INPUT   = False
SWAP_DISPLAY = False

WINDOW_NAME = "Route Recorder (L|R)"
THRESH_MASK = 0.7
ROW_TOL_Y   = 30

# ---- ìƒ‰ìƒ ë§¤í•‘ (YOLO í´ë˜ìŠ¤ëª… ë§¤í•‘) ----
COLOR_MAP = {
    'Hold_Red':(0,0,255),'Hold_Orange':(0,165,255),'Hold_Yellow':(0,255,255),
    'Hold_Green':(0,255,0),'Hold_Blue':(255,0,0),'Hold_Purple':(204,50,153),
    'Hold_Pink':(203,192,255),'Hold_Lime':(50,255,128),'Hold_Sky':(255,255,0),
    'Hold_White':(255,255,255),'Hold_Black':(30,30,30),'Hold_Gray':(150,150,150),
}
COLOR_ALIAS = {
    'red':'Hold_Red','orange':'Hold_Orange','yellow':'Hold_Yellow','green':'Hold_Green',
    'blue':'Hold_Blue','purple':'Hold_Purple','pink':'Hold_Pink','white':'Hold_White',
    'black':'Hold_Black','gray':'Hold_Gray','grey':'Hold_Gray','lime':'Hold_Lime','sky':'Hold_Sky',
}

# ===== ìœ í‹¸ =====
def parse_colors_arg(colors_arg:str|None):
    """--colors ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ í—ˆìš© í´ë˜ìŠ¤ëª… ë¦¬ìŠ¤íŠ¸ ë°˜í™˜. None ë˜ëŠ” allì´ë©´ None(=ì „ì²´ í—ˆìš©)."""
    if not colors_arg:
        human = ", ".join(sorted(COLOR_ALIAS.keys()))
        print(f"ğŸ¨ ì„ íƒ ê°€ëŠ¥í•œ ìƒ‰ìƒ: {human}")
        s = input("âœ… ì›í•˜ëŠ” í™€ë“œ ìƒ‰ìƒ ì…ë ¥ (ì‰¼í‘œêµ¬ë¶„, ì—”í„°=ì „ì²´): ").strip()
        if not s:
            print("â†’ ì „ì²´ í´ë˜ìŠ¤ í—ˆìš©"); return None
        colors_arg = s
    s = colors_arg.strip().lower()
    if s in {"all","*","ì „ì²´","ëª¨ë‘"}:
        print("â†’ ì „ì²´ í´ë˜ìŠ¤ í—ˆìš©"); return None
    allow = []
    for tok in [t.strip() for t in s.split(',') if t.strip()]:
        mapped = COLOR_ALIAS.get(tok)
        if mapped is None:
            print(f"âš ï¸ ìƒ‰ìƒ '{tok}' ì¸ì‹ ì‹¤íŒ¨ â†’ ë¬´ì‹œ")
        else:
            allow.append(mapped)
    allow = sorted(set(allow))
    if not allow:
        print("â†’ ìœ íš¨í•œ ìƒ‰ìƒì´ ì—†ì–´ ì „ì²´ í—ˆìš©ìœ¼ë¡œ ì „í™˜"); return None
    print("ğŸ¯ í—ˆìš© í´ë˜ìŠ¤:", ", ".join(allow))
    return allow


def load_stereo(npz_path:Path):
    S = np.load(str(npz_path), allow_pickle=True)
    K1, D1 = S["K1"], S["D1"]; K2, D2 = S["K2"], S["D2"]
    R1, R2 = S["R1"], S["R2"]; P1, P2 = S["P1"], S["P2"]
    W, H   = [int(x) for x in S["image_size"]]
    map1x, map1y = cv2.initUndistortRectifyMap(K1, D1, R1, P1, (W, H), cv2.CV_32FC1)
    map2x, map2y = cv2.initUndistortRectifyMap(K2, D2, R2, P2, (W, H), cv2.CV_32FC1)
    Tx = -P2[0,3] / P2[0,0]
    B  = float(abs(Tx))
    M  = np.array([0.5*Tx, 0.0, 0.0], dtype=np.float64)  # ì •ë³´ìš©
    return (map1x, map1y, map2x, map2y, P1, P2, (W, H), B, M)


def open_cams(idx1, idx2, size):
    W, H = size
    cap1 = cv2.VideoCapture(idx1, cv2.CAP_DSHOW)
    cap2 = cv2.VideoCapture(idx2, cv2.CAP_DSHOW)
    cap1.set(cv2.CAP_PROP_FRAME_WIDTH,  W); cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, H)
    cap2.set(cv2.CAP_PROP_FRAME_WIDTH,  W); cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, H)
    if not cap1.isOpened() or not cap2.isOpened():
        raise SystemExit("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤/ì—°ê²° í™•ì¸.")
    return cap1, cap2


def rectify(frame, mx, my, size):
    W, H = size
    if (frame.shape[1], frame.shape[0]) != (W, H):
        frame = cv2.resize(frame, (W, H))
    return cv2.remap(frame, mx, my, cv2.INTER_LINEAR)


def extract_holds_with_indices(frame_bgr, model, allow_classes:list[str]|None, mask_thresh=0.7, row_tol=50):
    h, w = frame_bgr.shape[:2]
    res = model(frame_bgr)[0]
    holds = []
    if res.masks is None: return []
    masks = res.masks.data; boxes = res.boxes; names = model.names
    for i in range(masks.shape[0]):
        cls_id = int(boxes.cls[i].item()); class_name = names[cls_id]
        if (allow_classes is not None) and (class_name not in allow_classes):
            continue
        mask = masks[i].cpu().numpy()
        mask_rs = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)
        binary = (mask_rs > mask_thresh).astype(np.uint8) * 255
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours: continue
        contour = max(contours, key=cv2.contourArea)
        M = cv2.moments(contour)
        if M["m00"] == 0: continue
        cx = int(M["m10"]/M["m00"]); cy = int(M["m01"]/M["m00"]) 
        holds.append({
            "class_name": class_name,
            "color": COLOR_MAP.get(class_name,(255,255,255)),
            "contour": contour, "center": (cx, cy),
            "conf": float(boxes.conf[i].item()),
        })
    if not holds: return []
    enriched = [{"cx": h_["center"][0], "cy": h_["center"][1], **h_} for h_ in holds]
    enriched.sort(key=lambda h: h["cy"])  # y ì •ë ¬
    rows, cur = [], [enriched[0]]
    for h_ in enriched[1:]:
        if abs(h_["cy"] - cur[0]["cy"]) < row_tol: cur.append(h_)
        else: rows.append(cur); cur = [h_]
    rows.append(cur)
    final_sorted = []
    for row in rows:
        row.sort(key=lambda h: h["cx"])  # x ì •ë ¬
        final_sorted.extend(row)
    for idx, h_ in enumerate(final_sorted):
        h_["hold_index"] = idx
    return final_sorted


def merge_holds_by_center(holds_lists, merge_dist_px=18):
    merged = []
    for holds in holds_lists:
        for h in holds:
            h = {k: v for k, v in h.items()}
            h.pop("hold_index", None)
            assigned = False
            for m in merged:
                dx = h["center"][0] - m["center"][0]
                dy = h["center"][1] - m["center"][1]
                if (dx*dx + dy*dy) ** 0.5 <= merge_dist_px:
                    area_h = cv2.contourArea(h["contour"])
                    area_m = cv2.contourArea(m["contour"])
                    if (area_h > area_m) or (abs(area_h - area_m) < 1e-6 and h.get("conf",0) > m.get("conf",0)):
                        m.update(h)
                    assigned = True
                    break
            if not assigned:
                merged.append(h)
    return merged


def assign_indices(holds, row_tol=50):
    if not holds: return []
    enriched = [{"cx": h["center"][0], "cy": h["center"][1], **h} for h in holds]
    enriched.sort(key=lambda h: h["cy"])  # y ì •ë ¬
    rows, cur = [], [enriched[0]]
    for h_ in enriched[1:]:
        if abs(h_["cy"] - cur[0]["cy"]) < row_tol: cur.append(h_)
        else: rows.append(cur); cur = [h_]
    rows.append(cur)
    final_sorted = []
    for row in rows:
        row.sort(key=lambda h: h["cx"])  # x ì •ë ¬
        final_sorted.extend(row)
    for idx, h_ in enumerate(final_sorted):
        h_["hold_index"] = idx
    return final_sorted


def triangulate_xy(P1, P2, ptL, ptR):
    xl = np.array(ptL, dtype=np.float64).reshape(2,1)
    xr = np.array(ptR, dtype=np.float64).reshape(2,1)
    Xh = cv2.triangulatePoints(P1, P2, xl, xr)
    X  = (Xh[:3] / Xh[3]).reshape(3)
    return X


def part_name_from_idx(landmark_idx:int)->str:
    if landmark_idx in (15,16):
        return "hand"
    else:
        return "foot"


# ===== ë©”ì¸ =====

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--npz",   default=str(NPZ_PATH))
    ap.add_argument("--model", default=str(MODEL_PATH))
    ap.add_argument("--colors", default=None, help="ì‰¼í‘œêµ¬ë¶„ ìƒ‰ìƒ(ì˜ˆ: orange,blue) / all | ì „ì²´ | *")
    ap.add_argument("--parts",  default="both", choices=["hands","feet","both"], help="ì ‘ì´‰ íŒë‹¨ì— ì‚¬ìš©í•  ì‹ ì²´ ë¶€ìœ„")
    ap.add_argument("--label",  default=None, help="íŒŒì¼ëª… ë¼ë²¨(ì„ íƒ)")
    ap.add_argument("--confirm_frames", type=int, default=4, help="ìë™ ì €ì¥ì„ ìœ„í•œ ì—°ì† í”„ë ˆì„ ìˆ˜(ìŠ¤ì¹¨ ë°©ì§€ ë””ë°”ìš´ìŠ¤)")
    ap.add_argument("--no_timestamp", action="store_true", help="CSVì— timestamp í•„ë“œë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŒ")
    ap.add_argument("--left_cam", type=int, default=None, help="ì™¼ìª½ ì¹´ë©”ë¼ ì¸ë±ìŠ¤(ê¸°ë³¸ 1)")
    ap.add_argument("--right_cam", type=int, default=None, help="ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼ ì¸ë±ìŠ¤(ê¸°ë³¸ 2)")
    ap.add_argument("--show_init", action="store_true", help="ì´ˆê¸° 10í”„ë ˆì„ YOLO ë‹¨ê³„ì—ì„œë„ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ")
    args = ap.parse_args()

    # ì§€ì—° ë¡œë“œ
    from ultralytics import YOLO
    import mediapipe as mp

    # ------- ìŠ¤í…Œë ˆì˜¤/ëª¨ë¸ ë¡œë“œ -------
    npz_path = Path(args.npz); model_path = Path(args.model)
    if not npz_path.exists():
        raise FileNotFoundError(f"ìŠ¤í…Œë ˆì˜¤ íŒŒë¼ë¯¸í„° íŒŒì¼ ì—†ìŒ: {npz_path}")
    if not model_path.exists():
        raise FileNotFoundError(f"YOLO ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")

    map1x, map1y, map2x, map2y, P1, P2, size, B, M = load_stereo(npz_path)
    W, H = size
    print(f"[Info] image_size={(W,H)}, baseline~{B:.2f} mm")

    # ìƒ‰ìƒ ì„¤ì •
    allow_classes = parse_colors_arg(args.colors)  # Noneì´ë©´ ì „ì²´ í—ˆìš©

    # ì¹´ë©”ë¼ ì—´ê¸°
    # ì¹´ë©”ë¼ ì¸ë±ìŠ¤ í™•ì •
    left_idx  = args.left_cam  if args.left_cam  is not None else CAM1_INDEX
    right_idx = args.right_cam if args.right_cam is not None else CAM2_INDEX
    capL_idx, capR_idx = (right_idx, left_idx) if SWAP_INPUT else (left_idx, right_idx)
    cap1, cap2 = open_cams(capL_idx, capR_idx, size)

    # YOLO ë¡œë“œ
    model = YOLO(str(model_path))

    # ------- ì´ˆê¸° 10í”„ë ˆì„: í™€ë“œ ê²€ì¶œ ë³‘í•© -------
    print(f"[Init] First 10 frames: YOLO seg & merge ...")
    L_sets, R_sets = [], []
    for _ in range(2):
        cap1.read(); cap2.read()
    for k in range(10):
        ok1, f1 = cap1.read(); ok2, f2 = cap2.read()
        if not (ok1 and ok2):
            raise SystemExit("ì´ˆê¸° í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨")
        Lr_k = rectify(f1, map1x, map1y, size)
        Rr_k = rectify(f2, map2x, map2y, size)
        L_sets.append(extract_holds_with_indices(Lr_k, model, allow_classes, THRESH_MASK, ROW_TOL_Y))
        R_sets.append(extract_holds_with_indices(Rr_k, model, allow_classes, THRESH_MASK, ROW_TOL_Y))
        if args.show_init:
            vis_init = np.hstack([Rr_k, Lr_k]) if SWAP_DISPLAY else np.hstack([Lr_k, Rr_k])
            cv2.putText(vis_init, f"Initializing YOLO: {k+1}/10", (20, 40), 0, 1.0, (0,0,0), 3, cv2.LINE_AA)
            cv2.putText(vis_init, f"Initializing YOLO: {k+1}/10", (20, 40), 0, 1.0, (0,255,255), 2, cv2.LINE_AA)
            cv2.imshow(WINDOW_NAME, vis_init)
            cv2.waitKey(1)
        print(f"  - frame {k+1}/10: L={len(L_sets[-1])}  R={len(R_sets[-1])}")

    holdsL = assign_indices(merge_holds_by_center(L_sets, 18), ROW_TOL_Y)
    holdsR = assign_indices(merge_holds_by_center(R_sets, 18), ROW_TOL_Y)
    if not holdsL or not holdsR:
        raise SystemExit("[Warn] í•œìª½ ë˜ëŠ” ì–‘ìª½ì—ì„œ í™€ë“œ ê²€ì¶œ ì‹¤íŒ¨")

    idxL = {h["hold_index"]: h for h in holdsL}
    idxR = {h["hold_index"]: h for h in holdsR}
    common_ids = sorted(set(idxL.keys()) & set(idxR.keys()))
    if not common_ids:
        raise SystemExit("[Warn] ì¢Œ/ìš° ê³µí†µ hold_indexê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ------- MediaPipe Pose -------
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)

    # ë¶€ìœ„ë³„ ì‚¬ìš© ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
    LM = {
        "hands": [15, 16],               # ì†ëª© (left_wrist, right_wrist)
        "feet":  [31, 32, 27, 28],       # ë°œë(index toe), ë°œëª©
    }
    if args.parts == "hands":
        lm_used = LM["hands"]
    elif args.parts == "feet":
        lm_used = LM["feet"]
    else:
        lm_used = LM["hands"] + LM["feet"]

    # ------- ë Œë”/ì…ë ¥ ë£¨í”„ -------
    cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)
    route = []  # list[dict]

    # ì ‘ì´‰ ëˆ„ì (ì—°ì† í”„ë ˆì„ ì¹´ìš´íŠ¸)
    contact = {hid: {"inside": False, "frames": 0, "part": None} for hid in common_ids}

    def save_csv(path:Path):
        path.parent.mkdir(parents=True, exist_ok=True)
        fieldnames = ["seq","hold_id","cxL","cyL","cxR","cyR","X_mm","Y_mm","Z_mm","contact_part"]
        if not args.no_timestamp:
            fieldnames.append("timestamp")
        with open(path, "w", newline='', encoding='utf-8') as f:
            w = csv.DictWriter(f, fieldnames=fieldnames)
            w.writeheader(); w.writerows(route)
        print(f"[Save] {path}  (rows={len(route)})")

    def append_step(hid:int, trigger_part:str):
        Lh = idxL.get(hid); Rh = idxR.get(hid)
        if not (Lh and Rh):
            print(f"[Skip] ID{hid} ì¢Œ/ìš° ë§¤ì¹­ ë¶ˆê°€"); return
        X = triangulate_xy(P1, P2, Lh["center"], Rh["center"])
        row = dict(
            seq=len(route), hold_id=int(hid),
            cxL=Lh["center"][0], cyL=Lh["center"][1],
            cxR=Rh["center"][0], cyR=Rh["center"][1],
            X_mm=float(X[0]), Y_mm=float(X[1]), Z_mm=float(X[2]),
            contact_part=trigger_part,
        )
        if not args.no_timestamp:
            row["timestamp"] = time.time()
        route.append(row)
        print(f"[Route] + seq {row['seq']}  ID{hid} ({trigger_part})  X=({row['X_mm']:.1f},{row['Y_mm']:.1f},{row['Z_mm']:.1f})")

    # ê¸°ë³¸ ì¶œë ¥ ê²½ë¡œ
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    fname = f"route_{ts}{('_'+args.label) if args.label else ''}.csv"
    out_path = ROUTES_DIR / fname

    while True:
        ok1, f1 = cap1.read(); ok2, f2 = cap2.read()
        if not (ok1 and ok2):
            print("[Warn] í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨"); break
        Lr = rectify(f1, map1x, map1y, size)
        Rr = rectify(f2, map2x, map2y, size)
        vis = np.hstack([Rr, Lr]) if SWAP_DISPLAY else np.hstack([Lr, Rr])

        # í™€ë“œ ì˜¤ë²„ë ˆì´
        for side, holds in (("L", holdsL), ("R", holdsR)):
            xoff = (W if SWAP_DISPLAY else 0) if side=="L" else (0 if SWAP_DISPLAY else W)
            for h in holds:
                cnt_shifted = h["contour"] + np.array([[[xoff, 0]]], dtype=h["contour"].dtype)
                cv2.drawContours(vis, [cnt_shifted], -1, h["color"], 2)
                cx, cy = h["center"]
                cv2.circle(vis, (cx+xoff, cy), 4, (255,255,255), -1)
                tag = f"ID:{h['hold_index']}"
                cv2.putText(vis, tag, (cx+xoff-10, cy+26), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3, cv2.LINE_AA)
                cv2.putText(vis, tag, (cx+xoff-10, cy+26), cv2.FONT_HERSHEY_SIMPLEX, 0.6, h["color"], 2, cv2.LINE_AA)

        # MediaPipe (ì™¼ìª½ í”„ë ˆì„ ê¸°ì¤€)
        result = pose.process(cv2.cvtColor(Lr, cv2.COLOR_BGR2RGB))
        coordsL = {}
        if result.pose_landmarks:
            hL, wL = Lr.shape[:2]
            for idx in lm_used:
                lm = result.pose_landmarks.landmark[idx]
                x, y = float(lm.x*wL), float(lm.y*hL)
                coordsL[idx] = (x, y)
                # draw
                left_xoff = (W if SWAP_DISPLAY else 0)
                cv2.circle(vis, (int(x)+left_xoff, int(y)), 6, (0,0,255), -1)

        # ì ‘ì´‰ í”„ë ˆì„ ì¹´ìš´íŠ¸ ê°±ì‹ 
        if coordsL:
            for hid in common_ids:
                inside_any = False
                used_part = None
                if hid in idxL:
                    cnt = idxL[hid]["contour"]
                    for lm_idx, xy in coordsL.items():
                        if cv2.pointPolygonTest(cnt, xy, False) >= 0:
                            inside_any = True
                            used_part = part_name_from_idx(lm_idx)
                            break
                c = contact[hid]
                if inside_any:
                    c["inside"] = True
                    c["frames"] += 1
                    c["part"] = used_part or c["part"]
                    if c["frames"] >= args.confirm_frames:
                        # ë§ˆì§€ë§‰ ì¶”ê°€ì™€ ë™ì¼ ì¢Œí‘œ ì¤‘ë³µ ë°©ì§€
                        if (not route) or (abs(route[-1]["cxL"] - idxL[hid]["center"][0]) > 1 or abs(route[-1]["cyL"] - idxL[hid]["center"][1]) > 1):
                            append_step(hid, trigger_part=c["part"] or "unknown")
                        # ë– ë‚  ë•Œê¹Œì§€ ì¬ê¸°ë¡ ë°©ì§€
                        c["frames"] = 10**9
                else:
                    c["inside"] = False
                    c["frames"] = 0
                    c["part"] = None

        # HUD
        cv2.putText(vis, f"Route len: {len(route)}   (M:add  Z:undo  R:reset  S:save  Q:quit)   parts={args.parts}  confirm_frames={args.confirm_frames}", (20, 28), 0, 0.7, (0,0,0), 3, cv2.LINE_AA)
        cv2.putText(vis, f"Route len: {len(route)}   (M:add  Z:undo  R:reset  S:save  Q:quit)   parts={args.parts}  confirm_frames={args.confirm_frames}", (20, 28), 0, 0.7, (0,255,255), 1, cv2.LINE_AA)
        
        cv2.imshow(WINDOW_NAME, vis)
        
        # í‚¤ ì…ë ¥
        k = cv2.waitKey(1) & 0xFF
        if k == ord('q'):
            break
        elif k == ord('m'):
            candidates = [(hid, c["frames"]) for hid,c in contact.items() if c["inside"]]
            if not candidates:
                print("[Info] ì ‘ì´‰ ì¤‘ì¸ í™€ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                candidates.sort(key=lambda t: -t[1])
                hid = candidates[0][0]
                c = contact[hid]
                append_step(hid, trigger_part=c["part"] or "manual")
        elif k == ord('z') and route:
            removed = route.pop()
            print(f"[Undo] seq {removed['seq']} ì œê±° (ID{removed['hold_id']})")
        elif k == ord('r'):
            route.clear(); print("[Reset] route cleared")
        elif k == ord('s'):
            save_csv(out_path)

    # ì¢…ë£Œ ì²˜ë¦¬
    cap1.release(); cap2.release(); cv2.destroyAllWindows()
    # ìë™ ì €ì¥
    if route:
        save_csv(out_path)


if __name__ == "__main__":
    main()
